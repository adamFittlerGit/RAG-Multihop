{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "from llama_index import Document\n",
    "\n",
    "STAGING=True\n",
    "\n",
    "# Helper functions for file handling (same as before)\n",
    "def save_list_to_json(lst, filename):\n",
    "    \"\"\" Save Files \"\"\"\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(lst, file)\n",
    "\n",
    "def rm_file(file_path):\n",
    "    \"\"\" Delete Files \"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"File {file_path} removed successfully.\")\n",
    "\n",
    "class JSONReader:\n",
    "    \"\"\"JSON reader.\"\"\"\n",
    "    def __init__(self, is_jsonl: Optional[bool] = False,) -> None:\n",
    "        \"\"\"Initialize with arguments.\"\"\"\n",
    "        super().__init__()\n",
    "        self.is_jsonl = is_jsonl\n",
    "\n",
    "    def load_data(self, input_file: str) -> List[Document]:\n",
    "        \"\"\"Load data from the input file.\"\"\"\n",
    "        documents = []\n",
    "        with open(input_file, 'r') as file:\n",
    "            load_data = json.load(file)\n",
    "        for data in load_data:\n",
    "            metadata = {\"title\": data['title'], \n",
    "                        \"published_at\": data['published_at'],\n",
    "                        \"source\":data['source']}\n",
    "            documents.append(Document(text=data['body'], metadata=metadata))\n",
    "        return documents\n",
    "\n",
    "\n",
    "    \n",
    "def gen_tfidf(corpus, queries, output_name):\n",
    "    print('Remove save file if exists.')\n",
    "    rm_file(output_name)\n",
    "\n",
    "    # Read the corpus json file\n",
    "    reader = JSONReader()\n",
    "    data = reader.load_data(corpus)\n",
    "    \n",
    "    print('Corpus Data')\n",
    "    print('--------------------------')\n",
    "    print(data[0])\n",
    "    print('--------------------------')\n",
    "\n",
    "    corpus_texts = [doc.text for doc in data]\n",
    "\n",
    "    # Create TF-IDF matrix for the corpus\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(corpus_texts)\n",
    "\n",
    "    print('TF-IDF Initialized ...')\n",
    "\n",
    "    # Parse the queries\n",
    "    with open(queries, 'r') as file:\n",
    "        query_data = json.load(file)\n",
    "\n",
    "    print('Query Data')\n",
    "    print('--------------------------')\n",
    "    print(query_data[0])\n",
    "    print('--------------------------')\n",
    "\n",
    "    retrieval_save_list = []\n",
    "    print(\"Running TF-IDF Retrieval ...\")\n",
    "\n",
    "    for data in tqdm(query_data):\n",
    "        query = data['query']\n",
    "        query_vector = vectorizer.transform([query])\n",
    "\n",
    "        # Calculate cosine similarity between the query and documents\n",
    "        scores = (X @ query_vector.T).toarray().flatten()\n",
    "\n",
    "        # Get top 10 results based on cosine similarity scores\n",
    "        top_results = sorted(zip(scores, corpus_texts), reverse=True)[:10]\n",
    "\n",
    "        retrieval_list = []\n",
    "        for score, text in top_results:\n",
    "            dic = {\n",
    "                'text': text,\n",
    "                'score': score\n",
    "            }\n",
    "            retrieval_list.append(dic)\n",
    "\n",
    "        # Save query, answers, and retrieved documents\n",
    "        save = {\n",
    "            'query': data['query'],\n",
    "            'answer': data['answer'],\n",
    "            'question_type': data.get('question_type', None),\n",
    "            'retrieval_list': retrieval_list,\n",
    "            'gold_list': data.get('evidence_list', [])\n",
    "        }\n",
    "        retrieval_save_list.append(save)\n",
    "\n",
    "    print('Retrieval complete. Saving Results...')\n",
    "    save_list_to_json(retrieval_save_list, output_name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if STAGING:\n",
    "        corpus = \"data/sample-corpus.json\"\n",
    "        queries = \"data/sample-rag.json\"\n",
    "    else:\n",
    "        corpus = \"data/corpus.json\"\n",
    "        queries = \"data/rag.json\"\n",
    "        \n",
    "    output_name = \"output/tfidf-retrieval.json\"\n",
    "\n",
    "    gen_tfidf(corpus, queries, output_name)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
